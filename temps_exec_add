P=65521, Coefficients tirés aléatoirement entre 0 et 4194304 (2048^2)


Sur GPU DEG blocks 1 thread : DEG=40   : temps execution aléatoire, ~0.44 en moyenne
	           	      DEG=32767 : idem ~0.41, borne int
	  	   	      DEG=65535: idem ~0.43, borne unsigned int
	  	   	      Le degré ne semble pas avoir d'impact sur le temps d'execution
	  	   	      Le programme ne fonctionne plus à partir à partir 65536 soit 2^16 :
		   	      A partir de 65536 apparition de valeurs erronées(potentiellement des adresses mémoires?)
			      		Est ce du au fait que que la borne du domaine des unsigned int est dépassée?

Sur GPU DEG blocks 512 threads: DEG=40    : temps execution aléatoire, ~0.41 en moyenne
		     		DEG=32767 : idem ~0.42, borne int
	  	     		DEG=65535 : idem ~0.42, borne unsigned int
	  	     		DEG=10 000 000 ~0.78 sec
	  	     			Le programme renvoie des valeurs erronées à partir de 100 000 000


Sur GPU 1 block DEG threads: 	DEG=40    : temps execution aléatoire, ~0.41 en moyenne
				Limité à 1024 threads: 
	  	     			Le programme renvoie des valeurs erronées à partir de 1025 threads


Dans le cadre de l'addition de polynomes le nombre de threads ne semble pas avoir d'impact sur le temps d'execution


Sur CPU:  DEG=40 : ~0.1ms
	  DEG=65535 : ~3ms
	  DEG= 10 000 000 : ~0.17s

On observe pour un degré de 10 000 000 un ratio de 4 entre leurs temps d'execution 



=> Limité à 1024 threads
